<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [MQ 中的一些优化策略](#mq-%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5)
  - [为什么高并发下程序会卡死](#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%A8%8B%E5%BA%8F%E4%BC%9A%E5%8D%A1%E6%AD%BB)
  - [高并发下的内存管理](#%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86)
  - [Kafka 如何实现高性能](#kafka-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD)
    - [使用批量消息提升服务端处理能力](#%E4%BD%BF%E7%94%A8%E6%89%B9%E9%87%8F%E6%B6%88%E6%81%AF%E6%8F%90%E5%8D%87%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%A4%84%E7%90%86%E8%83%BD%E5%8A%9B)
    - [使用顺序读提高磁盘的 IO 性能](#%E4%BD%BF%E7%94%A8%E9%A1%BA%E5%BA%8F%E8%AF%BB%E6%8F%90%E9%AB%98%E7%A3%81%E7%9B%98%E7%9A%84-io-%E6%80%A7%E8%83%BD)
    - [利用 PageCache 加速消息读写](#%E5%88%A9%E7%94%A8-pagecache-%E5%8A%A0%E9%80%9F%E6%B6%88%E6%81%AF%E8%AF%BB%E5%86%99)
    - [ZeroCopy：零拷贝技术](#zerocopy%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF)
- [参考](#%E5%8F%82%E8%80%83)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## MQ 中的一些优化策略

### 为什么高并发下程序会卡死

在微服务中我们每次接到一个请求，然后处理，中间可能创建了一些变量对象。之后随着业务的处理结束，期间创建的对象就需要被回收掉了。   

如果并发量高了   

请求量变大了，会有大量的对象变量被创建，可能在短期内就耗尽了服务器的内存资源，之后垃圾回收就会被动启动了，变量对象太多了，垃圾回收需要较长的时间。   

这时候进行的请求，就需要等待有内存资源才能被处理，垃圾回收刚刚结束，更多的请求立刻涌进来，迅速占满内存，再次被迫执行垃圾回收，进入了一个恶性循环。

所以大量请求过来了，就造成了服务器的卡死      

### 高并发下的内存管理   

垃圾回收是不可避免的，不过我们可以降低垃圾回收的频次。   

一般有两个策略   

1、尽量减少变量内存的申请，可以做到资源的复用。  

2、使用对象池，对于需要频繁使用，占用内存较大的一次性对象，我们可以考虑自行回收并重用这些对象，放入到对象池中。     

### Kafka 如何实现高性能

Kafka，单机写入TPS约在百万条/秒，来看下 kafka 都做了那些优化   

#### 使用批量消息提升服务端处理能力 

在 Kafka 内部，消息都是以“批”为单位处理的。  

- Producer 端  

在消息的生产端，产生了一条消息，然后发送。这时候 Kafka 不会把这个消息马上发出去，而是先把这个消息在内存中缓存起来，然后到了发送的时机，会把这些消息，一起发送出去。通俗的说就是攒一波再发送。   

- Broker 端

Broker 收到批处理的消息，不会做解析操作，还是当成一批数据来处理。

- Consumer 端

Consumer 在消费时同样也是当成一批数据来处理的，Consumer 从 Broker 拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。   

#### 使用顺序读提高磁盘的 IO 性能

对于磁盘来讲，顺序读写的效率要高于随机读写的效率。   

随机读写：需要先进性寻址，找到具体的写入位置，之后才进行读写操作。   

顺序读写：只需要寻址一次，之后就能在内存中依次写入内容了。   

顺序读写对比随机读写，少了每次的选寻址操作，所以效率比随机读写的高。    

Kafka 就是用了顺序读写的特性，它的存储设计非常简单，对于每个分区，它把从 Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。   

进一步优化，因为采用了顺序的写入，同时会写入到多个文件中。查询也是顺序的查询，如果要查询到某个消息的话，在文件很多，数据量很大的情况下，查询效率就是很低了。   

Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka 在写入小段文件的时候，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。  

<img src="/img/mq-kafka-index-cache.png"  alt="mq" align="center" />

#### 利用 PageCache 加速消息读写

<img src="/img/mq-kafka-cache.png"  alt="mq" align="center" />




#### ZeroCopy：零拷贝技术



## 参考  

【消息队列高手课】https://time.geekbang.org/column/intro/100032301       
【磁盘I/O那些事】https://tech.meituan.com/2017/05/19/about-desk-io.html     