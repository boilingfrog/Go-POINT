<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [消息队列常见问题处理](#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86)
  - [分布式事务](#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1)
    - [什么是分布式事务](#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1)
    - [常见的分布式事务解决方案](#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88)
    - [本地消息表-最终一致性](#%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8-%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7)
    - [MQ事务-最终一致性](#mq%E4%BA%8B%E5%8A%A1-%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7)
    - [RocketMQ中如何处理事务](#rocketmq%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E4%BA%8B%E5%8A%A1)
    - [Kafka中如何处理事务](#kafka%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E4%BA%8B%E5%8A%A1)
  - [消息防丢失](#%E6%B6%88%E6%81%AF%E9%98%B2%E4%B8%A2%E5%A4%B1)
  - [消息重复发送](#%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E5%8F%91%E9%80%81)
  - [处理消息的挤压](#%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF%E7%9A%84%E6%8C%A4%E5%8E%8B)
  - [参考](#%E5%8F%82%E8%80%83)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## 消息队列常见问题处理

### 分布式事务

#### 什么是分布式事务

我们的服务器从单机发展到拥有多台机器的分布式系统，各个系统之前需要借助于网络进行通信，原有单机中相对可靠的方法调用以及进程间通信方式已经没有办法使用，同时网络环境也是不稳定的，造成了我们多个机器之间的数据同步问题，这就是典型的分布式事务问题。  

在分布式事务中事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。分布式事务就是要保证不同节点之间的数据一致性。    

#### 常见的分布式事务解决方案

1、2PC(二阶段提交)方案 - 强一致性  

2、3PC(三阶段提交)方案  

3、TCC （Try-Confirm-Cancel）事务 - 最终一致性   

4、Saga事务 - 最终一致性

5、本地消息表 - 最终一致性  

6、MQ事务 - 最终一致性

这里重点关注下使用消息队列实现分布式的一致性，上面几种的分布式设计方案的具体细节可参见文章最后的引用链接      

#### 本地消息表-最终一致性   

消息的生产方，除了维护自己的业务逻辑之外，同时需要维护一个消息表。这个消息表里面记录的就是需要同步到别的服务的信息，当然这个消息表，每个消息都有一个状态值，来标识这个消息有没有被成功处理。   

发送放的业务逻辑以及消息表中数据的插入将在一个事务中完成，这样避免了`业务处理成功 + 事务消息发送失败`，或`业务处理失败 + 事务消息发送成功`，这个问题。    

举个栗子：   

我们假定目前有两个服务，订单服务，购物车服务，用户在购物车中对几个商品进行合并下单，之后需要情况购物车中刚刚已经下单的商品信息。      

**1、消息的生产方也就是订单服务，完成了自己的逻辑(对商品进行下单操作)然后把这个消息通过 mq 发送到需要进行数据同步的其他服务中，也就是我们栗子中的购物车服务。**

**2、其他服务(购物车服务)会监听这个队列；**  

1、如果收到这个消息，并且数据同步执行成功了，当然这也是一个本地事务，就通过 mq 回复消息的生产方(订单服务)消息已经处理了，然后生产方就能标识本次事务已经结束。如果是一个业务上的错误,就回复消息的生产方，需要进行数据回滚了。   

2、很久没收到这个消息，这种情况是不会发生的，消息的发送方会有一个定时的任务，会定时重试发送消息表中还没有处理的消息；

**3、消息的生产方(订单服务)如果收到消息回执；**  

1、成功的话就修改本次消息已经处理完，也就是本次分布式事务的同步已经完成；   

2、如果消息的结果是执行失败，同时在本地回滚本次事务，标识消息已经处理完成；   

3、如果消息丢失，也就是回执消息没有收到，这种情况也不太会发生，消息的发送方(订单服务)会有一个定时的任务，定时重试发送消息表中还没有处理的消息，下游的服务需要做幂等，可能会收到多次重复的消息，如果一个回复消息生产方中的某个回执信息丢失了，后面持续收到生产方的 mq 消息，然后再次回复消息的生产方回执信息，这样总能保证发送者能成功收到回执，消息的生产方在接收回执消息的时候也要做到幂等性。         

这里有两个很重要的操作：  

1、服务器处理消息需要是幂等的，消息的生产方和接收方都需要做到幂等性；  

2、发送放需要添加一个定时器来遍历重推未处理的消息，避免消息丢失，造成的事务执行断裂。  

改方案的优缺点   

优点：   

1、在设计层面上实现了消息数据的可靠性，不依赖消息中间件，弱化了对 mq 特性的依赖。  

2、简单，易于实现。  

缺点：   

主要是需要和业务数据绑定到一起，耦合性比较高，使用相同的数据库，会占用业务数据库的一些资源。     

#### MQ事务-最终一致性   

#### RocketMQ中如何处理事务

RocketMQ 中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且，RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。   

<img src="/img/mq-rocketmq-shiwu.png"  alt="mq" align="center" />

主要是两个方面，正常的事务提交和事务消息补偿   

正常的事务提交  

1、发送消息（half消息），这个 half 消息和普通消息的区别，在事务提交 之前，对于消费者来说，这个消息是不可见的。   

2、`MQ SERVER`写入信息，并且返回响应的结果；   

3、根据`MQ SERVER`响应的结果，决定是否执行本地事务,如果`MQ SERVER`写入信息成功执行本地事务，否则不执行；   

4、根据本地事务执行的状态，决定是否对事务进行 Commit 或者 Rollback。`MQ SERVER`收到 Commit，之后就会投递该消息到下游的订阅服务，下游的订阅服务就能进行数据同步，如果是 Rollback 则该消息就会被丢失；     

如果`MQ SERVER`没有收到 Commit 或者 Rollback 的消息，这种情况就需要进行补偿流程了    

补偿流程   

1、`MQ SERVER`如果没有收到来自消息发送方的 Commit 或者 Rollback 消息，就会向消息发送端也就是我们的服务器发起一次查询，查询当前消息的状态；  

2、消息发送方收到对应的查询请求，查询事务的状态，然后把状态重新推送给`MQ SERVER`，`MQ SERVER`就能之后后续的流程了。    

相比于本地消息表来处理分布式事务，MQ 事务是把原本应该在本地消息表中处理的逻辑放到了 MQ 中来完成。   

#### Kafka中如何处理事务

Kafka 中的事务解决问题，确保在一个事务中发送的多条信息，要么都成功，要么都失败。也就是保证对多个分区写入操作的原子性。   

通过配合 Kafka 的幂等机制来实现 Kafka 的 `Exactly Once`，满足了`读取-处理-写入`这种模式的应用程序。当然 Kafka 中的事务主要也是来处理这种模式的。          

什么是`读取-处理-写入`模式呢？   

栗如：在流计算中，用 Kafka 作为数据源，并且将计算结果保存到 Kafka 这种场景下，数据从 Kafka 的某个主题中消费，在计算集群中计算，再把计算结果保存在 Kafka 的其他主题中。这个过程中，要保证每条消息只被处理一次，这样才能保证最终结果的成功。Kafka 事务的原子性就保证了，读取和写入的原子性，两者要不一起成功，要不就一起失败回滚。     

这里来分析下 Kafka 的事务是如何实现的   

它的实现原理和 RocketMQ 的事务是差不多的，都是基于两阶段提交来实现的，在实现上可能更麻烦   

先来介绍下事务协调者，为了解决分布式事务问题，Kafka 引入了事务协调者这个角色，负责在服务端协调整个事务。这个协调者并不是一个独立的进程，而是 Broker 进程的一部分，协调者和分区一样通过选举来保证自身的可用性。   

Kafka 集群中也有一个特殊的用于记录事务日志的主题，里面记录的都是事务的日志。同时会有多个协调者的存在，每个协调者负责管理和使用事务日志中的几个分区。这样能够并行的执行事务，提高性能。    

下面看下具体的流程   

- 1、首先在开启事务的时候，生产者会给协调者发送一个开启事务的请求，协调者在事务日志中记录下事务ID;    

- 2、然后生产者开始发送事务消息给协调者，不过需要先发送消息告知协调者在哪个主题和分区，之后就正常的发送事务消息，这些事务消息不像 RocketMQ 会保存在特殊的队列中，Kafka 未提交的事务消息和普通的消息一样，只是在消费的时候依赖客户端进行过滤。   

- 3、消息发送完成，生产者根据自己的执行的状态对协调者进行事务的提交或者回滚；   

事务的提交   

1、协调者设置事务的状态为PrepareCommit，写入到事务日志中；   

2、协调者在每个分区中写入事务结束的标识，然后客户端就能把之前过滤的未提交的事务消息放行给消费端进行消费了；   

事务的回滚   

1、协调者设置事务的状态为PrepareAbort，写入到事务日志中；   

2、协调者在每个分区中写入事务回滚的标识，然后之前未提交的事务消息就能被丢弃了；  

这里引用一下【消息队列高手课中的图片】      

<img src="/img/kafka-shiwu.png"  alt="mq" align="center" />

### 消息防丢失

### 消息重复发送

### 处理消息的挤压

### 参考  

【消息队列高手课】https://time.geekbang.org/column/intro/100032301     
【消息队列设计精要】https://tech.meituan.com/2016/07/01/mq-design.html    
【RabbitMQ实战指南】https://book.douban.com/subject/27591386/      
【分布式事务最经典的七种解决方案】https://segmentfault.com/a/1190000040321750     
【分布式事务的实现原理】https://draveness.me/distributed-transaction-principle/   
【理解分布式事务】https://juejin.cn/post/6844903734753886216     
【设计(design)】https://github.com/apache/rocketmq/blob/master/docs/cn/design.md  
【Kafka 是如何实现事务的？】https://zhuanlan.zhihu.com/p/163683403    