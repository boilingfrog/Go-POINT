<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [AI 小说漫画推文](#ai-%E5%B0%8F%E8%AF%B4%E6%BC%AB%E7%94%BB%E6%8E%A8%E6%96%87)
  - [前言](#%E5%89%8D%E8%A8%80)
  - [整体的处理流程](#%E6%95%B4%E4%BD%93%E7%9A%84%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B)
  - [小说内容的提炼重新创作](#%E5%B0%8F%E8%AF%B4%E5%86%85%E5%AE%B9%E7%9A%84%E6%8F%90%E7%82%BC%E9%87%8D%E6%96%B0%E5%88%9B%E4%BD%9C)
  - [角色任务的一致性](#%E8%A7%92%E8%89%B2%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7)
  - [如何合成视频](#%E5%A6%82%E4%BD%95%E5%90%88%E6%88%90%E8%A7%86%E9%A2%91)
  - [总结](#%E6%80%BB%E7%BB%93)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## AI 小说漫画推文

### 前言

最近公司在考虑做 AI 小说漫画推文，将小说的内容转换成合适的场景图片，配合 AI 语音，加上小说内容内容字幕，将这些内容合成视频。  

将漫画，小说，听书，三者结合起来。简单听起来，实现难度不是很大，但是真的做起来，发现没有这么简单了。   

主要涉及到下面的几个难点：  

1、小说内容的提炼浓缩，原文的小说内容是比较臃长的，如果直接将内容不加修饰就制作成视频，吸引力不大；  

2、小说内容会出现不同的人物，使用 AI 生成视频，虽然生成的质量整体上是可以的，但是角色形象的一致性存在问题，可能第一个画面，小明还是个帅哥，后面就变成了大叔；  

3、合成视频的时候，小说内容，图片画面，播放音色，如果合成保持一致也是个问题。   

当前有人会说，手动处理就行了，当然全人工这些都不是问题，但是时间，人工成本就太大了。远远比不上 AI 的自动化生成。   

下面是自己进行的一些技术调研和尝试  

### 整体的处理流程

首先这里来梳理下整体使用到的技术和处理流程  

1、使用 gpt 生成对小说内容进行提炼，生成小说内容的分镜头；  

2、同样使用 gpt 对小说内容进行提炼，生成适合 sd 出图的关键词；  

3、因为出图的时候，小说内容中会有多个人物，并且每个人物会出现多次，所以我们需要控制好每个人物的形象特点；  

4、这里首先定义好每个人物的特点，sd 中人物可以结合是 lora 使用，不同的人物使用不同的 lora ，在 gpt 生成关键词的时候，对镜头中出现的既定人物使用我们定义好的人物形象来描述；  

5、对每个镜头的原文，通过指定的音色，调用语音合成服务生成一段语音朗读，这里有很多云服务都可以选用，openai,火山云，阿里云。。。。

6、通过 FFmpeg 将每个每个镜头的语音片段和图片，生成该镜头的视频，同时添加放大缩小的动态效果；  

7、最近按照顺序将所有的小说视频合成一个视频，通过剪影配上字幕，水印，调整视频的尺寸，整个视频完成。   

### 小说内容的提炼重新创作

小说推文，主要有三部分组成，内容，适配内容的图片，解说的语音。  

其中最重要的就是内容，和声音。图片的好坏就是锦上添花。   

所以如何把一个完整的小说进行提炼，总结提炼出一段30分钟左右的内容精华，不是一个很容易的事情。  

因为目前市面上流行的 ai 大模型，都对过长的文本支持的不是很友好，所以这块我的处理办法是先提炼小说每个章节大纲，然后让 ai 对总结出来的所有大纲，进行
内容的复写和核心亮点的提炼。  

### 角色任务的一致性

使用 sd 生图，保持人物的一致性是一个值得深究的问。  

目前市面上流行的出图工具，`mj,sd,Dall-E 3` 等，出图的能力都不是很差，但是在保持出图人物的一致性上，个人认为 sd 支持的更好一点，这里就如何使用 sd 来展开讨论。  

首先就是安装 sd ，这个网上资料一大推就不展开了，接下来就是寻找合适的模型，当然也可以自己训练。   

这里先聚焦在使用层面上，如何使用 sd 快速出图。  

1、模型  

模型主要从 Huggingface, github, Civitai 下载。  

Huggingface：主要提供主流 AI 绘画模型下载。  

github：也有一些小模型放在 github 下供下载使用。  

Civitai：AI艺术共享平台，可下载海量SD开源模型（推荐）。   






### 如何合成视频

有了图片，解读的语音，这里来看下如何把现有的素材合成一个带放大缩小效果的视频，这里主要使用 FFmpeg 来完成。  

将一段 mp3 和一张图片合成一个视频，根据音频文件的长度来生成视频。     

```
$ ffmpeg -loop 1 -i chapter-1.png -i chapter-1.mp3 -c:v libx264 -tune stillimage -c:a aac -b:a 192k -pix_fmt yuv420p -shortest chapter-1.mp4

-loop 1: 循环输入图片。1 表示无限循环，但由于 -shortest 选项的存在，视频将在音频结束时结束。
-i chapter-1.png: 指定输入文件，即你的图片。
-i chapter-1.mp3: 指定第二个输入文件，即你的音频文件。
-c:v libx264: 使用 libx264 编码器进行视频编码。
-tune stillimage: 优化编码器设置，适用于静态图片视频。
-c:a aac: 使用AAC编码音频。
-b:a 192k: 设置音频比特率为192k。
-pix_fmt yuv420p: 设置像素格式，yuv420p 是大多数视频播放器和平台所兼容的。
-shortest: 输出视频的长度将与较短的输入流（在这种情况下是音频流）相匹配。
chapter-1.mp4: 输出文件的名称和格式。
```

有了每个镜头的视频，然后最后一步就是将所有的视频通过 ffmpeg 合成一个最后的长视频。  

如果所有视频文件的格式（编解码器、分辨率、帧率等）都相同，你可以使用 concat 协议。首先，创建一个文本文件（例如 inputs.txt），列出所有视频文件：  

```
$ cat input.txt
file 'output_0.mp4'
file 'output_1.mp4'
file 'output_2.mp4'
```

运行以下 ffmpeg 命令  

```
$ ffmpeg -f concat -safe 0 -i input.txt -c copy output.mp4
```

这里 `-c copy` 表示直接复制视频和音频流，不进行重新编码，这会非常快。   

### 总结


