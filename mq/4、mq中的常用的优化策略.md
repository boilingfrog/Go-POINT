<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [MQ 中的一些优化策略](#mq-%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5)
  - [为什么高并发下程序会卡死](#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%A8%8B%E5%BA%8F%E4%BC%9A%E5%8D%A1%E6%AD%BB)
  - [高并发下的内存管理](#%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86)
  - [Kafka 如何实现高性能](#kafka-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD)
    - [使用批量消息提升服务端处理能力](#%E4%BD%BF%E7%94%A8%E6%89%B9%E9%87%8F%E6%B6%88%E6%81%AF%E6%8F%90%E5%8D%87%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%A4%84%E7%90%86%E8%83%BD%E5%8A%9B)
    - [使用顺序读提高磁盘的 IO 性能](#%E4%BD%BF%E7%94%A8%E9%A1%BA%E5%BA%8F%E8%AF%BB%E6%8F%90%E9%AB%98%E7%A3%81%E7%9B%98%E7%9A%84-io-%E6%80%A7%E8%83%BD)
    - [利用 PageCache 加速消息读写](#%E5%88%A9%E7%94%A8-pagecache-%E5%8A%A0%E9%80%9F%E6%B6%88%E6%81%AF%E8%AF%BB%E5%86%99)
    - [ZeroCopy：零拷贝技术](#zerocopy%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF)
  - [使用硬件同步原语（CAS）替代锁](#%E4%BD%BF%E7%94%A8%E7%A1%AC%E4%BB%B6%E5%90%8C%E6%AD%A5%E5%8E%9F%E8%AF%ADcas%E6%9B%BF%E4%BB%A3%E9%94%81)
  - [参考](#%E5%8F%82%E8%80%83)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## MQ 中的一些优化策略

### 为什么高并发下程序会卡死

在微服务中我们每次接到一个请求，然后处理，中间可能创建了一些变量对象。之后随着业务的处理结束，期间创建的对象就需要被回收掉了。   

如果并发量高了   

请求量变大了，会有大量的对象变量被创建，可能在短期内就耗尽了服务器的内存资源，之后垃圾回收就会被动启动了，变量对象太多了，垃圾回收需要较长的时间。   

这时候进行的请求，就需要等待有内存资源才能被处理，垃圾回收刚刚结束，更多的请求立刻涌进来，迅速占满内存，再次被迫执行垃圾回收，进入了一个恶性循环。

所以大量请求过来了，就造成了服务器的卡死      

### 高并发下的内存管理   

垃圾回收是不可避免的，不过我们可以降低垃圾回收的频次。   

一般有两个策略   

1、尽量减少变量内存的申请，可以做到资源的复用。  

2、使用对象池，对于需要频繁使用，占用内存较大的一次性对象，我们可以考虑自行回收并重用这些对象，放入到对象池中。     

### Kafka 如何实现高性能

Kafka，单机写入TPS约在百万条/秒，来看下 kafka 都做了那些优化   

#### 使用批量消息提升服务端处理能力 

在 Kafka 内部，消息都是以“批”为单位处理的。  

- Producer 端  

在消息的生产端，产生了一条消息，然后发送。这时候 Kafka 不会把这个消息马上发出去，而是先把这个消息在内存中缓存起来，然后到了发送的时机，会把这些消息，一起发送出去。通俗的说就是攒一波再发送。   

- Broker 端

Broker 收到批处理的消息，不会做解析操作，还是当成一批数据来处理。

- Consumer 端

Consumer 在消费时同样也是当成一批数据来处理的，Consumer 从 Broker 拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。   

#### 使用顺序读提高磁盘的 IO 性能

对于磁盘来讲，顺序读写的效率要高于随机读写的效率。   

随机读写：需要先进性寻址，找到具体的写入位置，之后才进行读写操作。   

顺序读写：只需要寻址一次，之后就能在内存中依次写入内容了。   

顺序读写对比随机读写，少了每次的选寻址操作，所以效率比随机读写的高。    

Kafka 就是用了顺序读写的特性，它的存储设计非常简单，对于每个分区，它把从 Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。   

进一步优化，因为采用了顺序的写入，同时会写入到多个文件中。查询也是顺序的查询，如果要查询到某个消息的话，在文件很多，数据量很大的情况下，查询效率就是很低了。   

Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka 在写入小段文件的时候，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。  

借用[磁盘I/O那些事](https://tech.meituan.com/2017/05/19/about-desk-io.html)中的图片   

<img src="/img/mq/mq-kafka-index-cache.png"  alt="mq" align="center" />

#### 利用 PageCache 加速消息读写

<img src="/img/mq/mq-kafka-cache.png"  alt="mq" align="center" />

引入Cache层的目的是为了提高Linux操作系统对磁盘访问的性能。Cache层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在Cache中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。  

Kafka 会使用 PageCache 加速读写。Kafka 会先把文件写入到 PageCache 中，之后在分批的刷到磁盘中。   

Producer将数据发送到Broker，PageCache 会缓存这部分数据。当有 Consumer 消费的时候会从 PageCache 读取数据，当 PageCache 空间不足时，会按照LRU策略开始淘汰数据，如果 PageCache 没有数据的时候，这时候操作系统会引发一个缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到 PageCache 中，然后应用程序再从 PageCache 中继续把数据读出来，这时会真正读一次磁盘上的文件，这个读的过程就会比较慢。   

#### ZeroCopy：零拷贝技术

Kafka 的服务端在消费过程中，还使用了一种“零拷贝”的操作系统特性来进一步提升消费的性能。  

我们知道，在服务端，处理消费的大致逻辑是这样的：  

- 首先，从文件中找到消息数据，读到内存中；  

- 然后，把消息通过网络发给客户端。  

这个过程中，数据实际上做了 2 次或者 3 次复制：  

1、从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉；  

2、从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内存；  

3、从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架的 API 发送数据的过程。  

Kafka 使用零拷贝技术可以把这个复制次数减少一次，上面的 2、3 步骤两次复制合并成一次复制。直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。   

### 使用硬件同步原语（CAS）替代锁  

CAS（Compare and Swap），它的字面意思是：先比较，再交换。  

对于原语来讲，它们都是由计算机硬件，具体说就是 CPU 提供的实现，可以保证操作的原子性。原子操作本就是不可分割的，所以不存在并发的安全问题。   

### 参考  

【消息队列高手课】https://time.geekbang.org/column/intro/100032301       
【磁盘I/O那些事】https://tech.meituan.com/2017/05/19/about-desk-io.html     